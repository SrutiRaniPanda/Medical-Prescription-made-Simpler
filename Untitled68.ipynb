{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsrtWsFFO8EhcUvBeBZFU/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrutiRaniPanda/Medical-Prescription-made-Simpler/blob/main/Untitled68.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Prescription Reader & Simplifier - Google Colab Version"
      ],
      "metadata": {
        "id": "gwMwVGKW8vbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run this code in Google Colab for processing medical prescriptions\n",
        "\n",
        "# Install required packages\n",
        "!pip install opencv-python-headless pillow pytesseract googletrans==4.0.0-rc1 pandas reportlab fpdf2\n",
        "!apt-get update\n",
        "!apt-get install tesseract-ocr\n",
        "!apt-get install libtesseract-dev\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import re\n",
        "import pandas as pd\n",
        "from googletrans import Translator\n",
        "from fpdf import FPDF\n",
        "import io\n",
        "import base64\n",
        "from datetime import datetime\n",
        "import json\n",
        "import requests\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CHbCMLB9qcn",
        "outputId": "bc6afda2-f1a2-48ba-ba56-eec108e279f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting fpdf2\n",
            "  Downloading fpdf2-2.8.3-py2.py3-none-any.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.7.9)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from reportlab) (3.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from fpdf2) (0.7.1)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from fpdf2) (4.58.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading reportlab-4.4.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fpdf2-2.8.3-py2.py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m245.7/245.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=2aa13bf215c0abcb0c9dfc0a3329325dcdab1c9fe818b5f658008a62a77cd9d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, reportlab, pytesseract, idna, hstspreload, h2, fpdf2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: hyperframe\n",
            "    Found existing installation: hyperframe 6.1.0\n",
            "    Uninstalling hyperframe-6.1.0:\n",
            "      Successfully uninstalled hyperframe-6.1.0\n",
            "  Attempting uninstall: hpack\n",
            "    Found existing installation: hpack 4.1.0\n",
            "    Uninstalling hpack-4.1.0:\n",
            "      Successfully uninstalled hpack-4.1.0\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: h2\n",
            "    Found existing installation: h2 4.2.0\n",
            "    Uninstalling h2-4.2.0:\n",
            "      Successfully uninstalled h2-4.2.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.24.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio-client 1.10.1 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n",
            "langsmith 0.4.4 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio 5.31.0 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.13.3 which is incompatible.\n",
            "openai 1.93.3 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-3.0.4 fpdf2-2.8.3 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 pytesseract-0.3.13 reportlab-4.4.2 rfc3986-1.5.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,103 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,266 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,758 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,104 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,420 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,569 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,963 kB]\n",
            "Fetched 26.6 MB in 4s (6,559 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 43 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.5 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 1s (3,292 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.5_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalPrescriptionProcessor:\n",
        "    def __init__(self):\n",
        "        self.translator = Translator()\n",
        "        self.medical_abbreviations = {\n",
        "            # Frequency abbreviations\n",
        "            'OD': 'once daily',\n",
        "            'BD': 'twice daily',\n",
        "            'BID': 'twice daily',\n",
        "            'TID': 'three times daily',\n",
        "            'QID': 'four times daily',\n",
        "            'PRN': 'as needed',\n",
        "            'SOS': 'if required',\n",
        "            'QH': 'every hour',\n",
        "            'Q2H': 'every 2 hours',\n",
        "            'Q4H': 'every 4 hours',\n",
        "            'Q6H': 'every 6 hours',\n",
        "            'Q8H': 'every 8 hours',\n",
        "            'Q12H': 'every 12 hours',\n",
        "            'HS': 'at bedtime',\n",
        "            'AC': 'before meals',\n",
        "            'PC': 'after meals',\n",
        "            'STAT': 'immediately',\n",
        "\n",
        "            # Dosage forms\n",
        "            'TAB': 'tablet',\n",
        "            'TABS': 'tablets',\n",
        "            'CAP': 'capsule',\n",
        "            'CAPS': 'capsules',\n",
        "            'SYP': 'syrup',\n",
        "            'SYRUP': 'syrup',\n",
        "            'INJ': 'injection',\n",
        "            'DROPS': 'drops',\n",
        "            'OINT': 'ointment',\n",
        "            'CREAM': 'cream',\n",
        "            'GEL': 'gel',\n",
        "            'LOTION': 'lotion',\n",
        "            'POWDER': 'powder',\n",
        "            'SACHETS': 'sachets',\n",
        "\n",
        "            # Routes\n",
        "            'PO': 'by mouth',\n",
        "            'IV': 'intravenous',\n",
        "            'IM': 'intramuscular',\n",
        "            'SC': 'subcutaneous',\n",
        "            'TOP': 'topical',\n",
        "            'EYE': 'eye',\n",
        "            'EAR': 'ear',\n",
        "            'NASAL': 'nasal',\n",
        "\n",
        "            # Units\n",
        "            'MG': 'milligrams',\n",
        "            'G': 'grams',\n",
        "            'ML': 'milliliters',\n",
        "            'L': 'liters',\n",
        "            'IU': 'international units',\n",
        "            'MCG': 'micrograms',\n",
        "            'TSP': 'teaspoon',\n",
        "            'TBSP': 'tablespoon',\n",
        "        }\n",
        "\n",
        "        self.languages = {\n",
        "            'English': 'en',\n",
        "            'Hindi': 'hi',\n",
        "            'Marathi': 'mr',\n",
        "            'Tamil': 'ta',\n",
        "            'Telugu': 'te',\n",
        "            'Bengali': 'bn',\n",
        "            'Gujarati': 'gu',\n",
        "            'Kannada': 'kn',\n",
        "            'Malayalam': 'ml',\n",
        "            'Punjabi': 'pa',\n",
        "            'Urdu': 'ur'\n",
        "        }\n",
        "\n",
        "        # Add more common Indian medicines\n",
        "        self.common_medicines = {\n",
        "            'paracetamol': 'fever and pain reliever',\n",
        "            'aspirin': 'pain reliever and blood thinner',\n",
        "            'ibuprofen': 'pain and inflammation reliever',\n",
        "            'amoxicillin': 'antibiotic',\n",
        "            'azithromycin': 'antibiotic',\n",
        "            'metformin': 'diabetes medication',\n",
        "            'amlodipine': 'blood pressure medication',\n",
        "            'atorvastatin': 'cholesterol medication',\n",
        "            'omeprazole': 'acid reflux medication',\n",
        "            'cetirizine': 'allergy medication',\n",
        "            'pantoprazole': 'acid reflux medication',\n",
        "            'losartan': 'blood pressure medication',\n",
        "            'clopidogrel': 'blood thinner',\n",
        "            'levothyroxine': 'thyroid medication',\n",
        "            'insulin': 'diabetes medication',\n",
        "            'ciprofloxacin': 'antibiotic',\n",
        "            'dolo': 'fever and pain reliever',\n",
        "            'crocin': 'fever and pain reliever',\n",
        "            'combiflam': 'pain and fever reliever',\n",
        "            'disprin': 'pain reliever',\n",
        "            'digene': 'antacid',\n",
        "            'eno': 'antacid',\n",
        "            'vicks': 'cough and cold relief',\n",
        "            'zodox': 'antibiotic (cefpodoxime)',\n",
        "            'qutpin': 'antipsychotic medication',\n",
        "            'ativan': 'anxiety medication',\n",
        "            'rivotril': 'seizure and anxiety medication',\n",
        "            'sertraline': 'antidepressant',\n",
        "            'serta': 'antidepressant',\n",
        "            'clonazepam': 'anxiety and seizure medication',\n",
        "            'lorazepam': 'anxiety medication',\n",
        "            'cefpodoxime': 'antibiotic',\n",
        "            'quetiapine': 'antipsychotic medication',\n",
        "            'si zodox': 'antibiotic (cefpodoxime)',\n",
        "            'plus': 'combination medication',\n",
        "            'nexium': 'acid reflux medication',\n",
        "            'rabeprazole': 'acid reflux medication',\n",
        "            'domperidone': 'nausea and vomiting medication'\n",
        "        }\n",
        "\n",
        "    def preprocess_image(self, image_path):\n",
        "        \"\"\"Preprocess image for better OCR results\"\"\"\n",
        "        try:\n",
        "            # Read image\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                raise Exception(\"Could not read image file\")\n",
        "\n",
        "            # Convert to grayscale\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Apply denoising\n",
        "            denoised = cv2.fastNlMeansDenoising(gray)\n",
        "\n",
        "            # Apply adaptive thresholding\n",
        "            thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                         cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "            # Apply morphological operations to clean up the image\n",
        "            kernel = np.ones((1, 1), np.uint8)\n",
        "            cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "            # Save preprocessed image for viewing\n",
        "            cv2.imwrite('/content/preprocessed_image.png', cleaned)\n",
        "\n",
        "            return cleaned\n",
        "        except Exception as e:\n",
        "            print(f\"Error preprocessing image: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def extract_text_from_image(self, image_path):\n",
        "        \"\"\"Extract text from image using OCR with multiple configurations\"\"\"\n",
        "        try:\n",
        "            # Try different OCR configurations for better results\n",
        "            configs = [\n",
        "                r'--oem 3 --psm 6',  # Uniform block of text\n",
        "                r'--oem 3 --psm 4',  # Single column of text\n",
        "                r'--oem 3 --psm 3',  # Fully automatic page segmentation\n",
        "                r'--oem 3 --psm 1',  # Automatic page segmentation with OSD\n",
        "            ]\n",
        "\n",
        "            best_text = \"\"\n",
        "            max_length = 0\n",
        "\n",
        "            # Read original image\n",
        "            original_img = cv2.imread(image_path)\n",
        "\n",
        "            # Try different preprocessing approaches\n",
        "            preprocessing_methods = [\n",
        "                self.preprocess_image,\n",
        "                self.preprocess_image_alternative,\n",
        "                self.preprocess_image_simple\n",
        "            ]\n",
        "\n",
        "            for preprocess_func in preprocessing_methods:\n",
        "                try:\n",
        "                    processed_img = preprocess_func(image_path)\n",
        "                    if processed_img is None:\n",
        "                        continue\n",
        "\n",
        "                    for config in configs:\n",
        "                        try:\n",
        "                            text = pytesseract.image_to_string(processed_img, config=config)\n",
        "                            if len(text) > max_length:\n",
        "                                max_length = len(text)\n",
        "                                best_text = text\n",
        "                        except:\n",
        "                            continue\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            # If still no good result, try with original image\n",
        "            if len(best_text) < 50:\n",
        "                try:\n",
        "                    gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
        "                    text = pytesseract.image_to_string(gray)\n",
        "                    if len(text) > len(best_text):\n",
        "                        best_text = text\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            return best_text.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting text: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def preprocess_image_alternative(self, image_path):\n",
        "        \"\"\"Alternative preprocessing method\"\"\"\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                return None\n",
        "\n",
        "            # Convert to grayscale\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Apply Gaussian blur\n",
        "            blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "            # Apply threshold\n",
        "            _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "            # Morphological operations\n",
        "            kernel = np.ones((2, 2), np.uint8)\n",
        "            processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "            return processed\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in alternative preprocessing: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def preprocess_image_simple(self, image_path):\n",
        "        \"\"\"Simple preprocessing method\"\"\"\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                return None\n",
        "\n",
        "            # Convert to grayscale\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Simple threshold\n",
        "            _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "            return thresh\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in simple preprocessing: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Clean and preprocess extracted text\"\"\"\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "        # Remove special characters but keep medical ones\n",
        "        text = re.sub(r'[^\\w\\s\\-\\(\\)\\.\\,\\:\\;\\/]', '', text)\n",
        "\n",
        "        # Convert to uppercase for consistency\n",
        "        text = text.upper()\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    def extract_medicine_info(self, text):\n",
        "        \"\"\"Extract medicine information using improved patterns for real prescriptions\"\"\"\n",
        "        medicines = []\n",
        "        lines = text.split('\\n')\n",
        "\n",
        "        # Medicine indicators - more flexible patterns\n",
        "        medicine_indicators = [\n",
        "            r'^\\s*\\d+[\\.\\)]\\s*',  # 1. or 1)\n",
        "            r'^\\s*[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\\s*',  # Circled numbers\n",
        "            r'^\\s*[a-z]\\)\\s*',  # a) b) c)\n",
        "            r'^\\s*R\\s*',  # R (prescription symbol)\n",
        "            r'^\\s*TAB\\s*',  # Direct tablet mention\n",
        "            r'^\\s*CAP\\s*',  # Direct capsule mention\n",
        "            r'^\\s*SYP\\s*',  # Direct syrup mention\n",
        "            r'^\\s*INJ\\s*',  # Direct injection mention\n",
        "        ]\n",
        "\n",
        "        # Skip patterns - lines to ignore\n",
        "        skip_patterns = [\n",
        "            r'DR\\.?\\s+',\n",
        "            r'DOCTOR',\n",
        "            r'CLINIC',\n",
        "            r'HOSPITAL',\n",
        "            r'PHONE',\n",
        "            r'ADDRESS',\n",
        "            r'CONSULTATION',\n",
        "            r'PATIENT',\n",
        "            r'DATE',\n",
        "            r'REGD?\\.?\\s*NO',\n",
        "            r'TELEPHONE',\n",
        "            r'MOBILE',\n",
        "            r'EMAIL',\n",
        "            r'COUNSELLED',\n",
        "            r'CONTINUE',\n",
        "            r'CALL\\s+ME',\n",
        "            r'NEXT\\s+VISIT',\n",
        "            r'FOLLOW\\s+UP',\n",
        "            r'ADVISED',\n",
        "            r'SIGNATURE',\n",
        "            r'PLOT\\s+NO',\n",
        "            r'ROAD',\n",
        "            r'COLONY',\n",
        "            r'CITY',\n",
        "            r'PINCODE',\n",
        "            r'^\\s*\\d{2,4}$',  # Just numbers (likely phone/reg numbers)\n",
        "            r'^\\s*[A-Z]\\s*$',  # Single letters\n",
        "            r'^\\s*[\\-\\=\\_]{3,}',  # Lines/separators\n",
        "        ]\n",
        "\n",
        "        for line_num, line in enumerate(lines):\n",
        "            original_line = line\n",
        "            line = line.strip()\n",
        "\n",
        "            # Skip empty lines or very short lines\n",
        "            if not line or len(line) < 3:\n",
        "                continue\n",
        "\n",
        "            # Skip lines that match skip patterns\n",
        "            if any(re.search(pattern, line.upper()) for pattern in skip_patterns):\n",
        "                continue\n",
        "\n",
        "            # Check if line contains medicine indicators or looks like medicine\n",
        "            is_medicine_line = False\n",
        "\n",
        "            # Check for medicine indicators\n",
        "            for indicator in medicine_indicators:\n",
        "                if re.search(indicator, line, re.IGNORECASE):\n",
        "                    is_medicine_line = True\n",
        "                    break\n",
        "\n",
        "            # Check if line contains typical medicine patterns\n",
        "            if not is_medicine_line:\n",
        "                medicine_patterns = [\n",
        "                    r'TAB\\s+\\w+',  # TAB followed by name\n",
        "                    r'CAP\\s+\\w+',  # CAP followed by name\n",
        "                    r'SYP\\s+\\w+',  # SYP followed by name\n",
        "                    r'INJ\\s+\\w+',  # INJ followed by name\n",
        "                    r'\\w+\\s+\\d+\\s*MG',  # Name followed by dosage\n",
        "                    r'\\w+\\s+PLUS',  # Names with PLUS\n",
        "                    r'^\\s*\\w+\\s+\\w+.*(?:MG|ML|G)\\b',  # Two words followed by units\n",
        "                    r'^\\s*\\w{4,}',  # Words with 4+ characters (likely medicine names)\n",
        "                ]\n",
        "\n",
        "                for pattern in medicine_patterns:\n",
        "                    if re.search(pattern, line.upper()):\n",
        "                        is_medicine_line = True\n",
        "                        break\n",
        "\n",
        "            if is_medicine_line:\n",
        "                # Extract medicine name - more flexible approach\n",
        "                medicine_name = \"\"\n",
        "\n",
        "                # Remove common prefixes\n",
        "                cleaned_line = re.sub(r'^\\s*\\d+[\\.\\)]\\s*', '', line)\n",
        "                cleaned_line = re.sub(r'^\\s*[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\\s*', '', cleaned_line)\n",
        "                cleaned_line = re.sub(r'^\\s*[a-z]\\)\\s*', '', cleaned_line)\n",
        "                cleaned_line = re.sub(r'^\\s*R\\s*', '', cleaned_line)\n",
        "\n",
        "                # Extract medicine name (everything before dosage or frequency indicators)\n",
        "                name_patterns = [\n",
        "                    r'^(.*?)\\s+\\d+\\s*(?:MG|ML|G|MCG|IU)',  # Before dosage\n",
        "                    r'^(.*?)\\s+(?:OD|BD|BID|TID|QID|PRN|SOS)',  # Before frequency\n",
        "                    r'^(.*?)\\s+(?:MORNING|NIGHT|DAILY)',  # Before timing\n",
        "                    r'^(.*?)\\s+\\d+\\s*(?:X|TIMES)',  # Before frequency count\n",
        "                    r'^(.*?)\\s+\\d+\\-\\d+\\-\\d+',  # Before pattern like 1-0-1\n",
        "                    r'^(.+?)(?:\\s+X\\s+|\\s+FOR\\s+|\\s+TAKE\\s+)',  # Before instruction words\n",
        "                    r'^(.+)',  # Entire line as fallback\n",
        "                ]\n",
        "\n",
        "                for pattern in name_patterns:\n",
        "                    match = re.search(pattern, cleaned_line.strip(), re.IGNORECASE)\n",
        "                    if match:\n",
        "                        medicine_name = match.group(1).strip()\n",
        "                        break\n",
        "\n",
        "                # Clean up the medicine name\n",
        "                medicine_name = re.sub(r'\\s+', ' ', medicine_name)\n",
        "                medicine_name = medicine_name.strip()\n",
        "\n",
        "                # Skip if name is too short or looks like non-medicine\n",
        "                if len(medicine_name) < 2:\n",
        "                    continue\n",
        "\n",
        "                # Extract dosage information - more flexible\n",
        "                dosage_patterns = [\n",
        "                    r'(\\d+(?:\\.\\d+)?)\\s*(?:MG|ML|G|MCG|IU)\\b',\n",
        "                    r'(\\d+(?:\\.\\d+)?)\\s*(?:MILLIGRAMS?|GRAMS?|MILLILITERS?)',\n",
        "                    r'(\\d+(?:\\.\\d+)?)\\s*(?:MG|ML|G)\\b',\n",
        "                ]\n",
        "\n",
        "                dosage = \"As prescribed\"\n",
        "                for pattern in dosage_patterns:\n",
        "                    dosage_match = re.search(pattern, line.upper())\n",
        "                    if dosage_match:\n",
        "                        dosage = dosage_match.group(0)\n",
        "                        break\n",
        "\n",
        "                # Extract frequency patterns - more comprehensive\n",
        "                frequency_patterns = [\n",
        "                    r'(\\d+\\-\\d+\\-\\d+)',  # Pattern like 1-0-1\n",
        "                    r'(\\d+)\\s*(?:X|TIMES?)\\s*(?:DAILY|DAY|A\\s*DAY)',  # Pattern like 2 times daily\n",
        "                    r'(OD|BD|BID|TID|QID|PRN|SOS|HS|AC|PC|STAT)\\b',  # Medical abbreviations\n",
        "                    r'(\\d+)\\s*(?:HOURLY|HOURS?)',  # Hourly patterns\n",
        "                    r'(ONCE|TWICE|THRICE)\\s*(?:DAILY|A\\s*DAY)',  # Word patterns\n",
        "                    r'(MORNING|NIGHT|EVENING)\\s*(?:ONLY)?',  # Time-based\n",
        "                    r'(\\d+)\\s*(?:TABLET|TAB|CAPSULE|CAP|TEASPOON|TSP)',  # Count-based\n",
        "                ]\n",
        "\n",
        "                frequency = \"As needed\"\n",
        "                for pattern in frequency_patterns:\n",
        "                    freq_match = re.search(pattern, line.upper())\n",
        "                    if freq_match:\n",
        "                        frequency = freq_match.group(1)\n",
        "                        break\n",
        "\n",
        "                # Extract duration - more patterns\n",
        "                duration_patterns = [\n",
        "                    r'(?:FOR|X)\\s*(\\d+)\\s*(?:DAYS?|WEEKS?|MONTHS?)',\n",
        "                    r'(\\d+)\\s*(?:DAYS?|WEEKS?|MONTHS?)\\s*(?:COURSE|TREATMENT)?',\n",
        "                    r'(?:CONTINUE|CONT)\\s*(?:FOR)?\\s*(\\d+)\\s*(?:DAYS?|WEEKS?)',\n",
        "                ]\n",
        "\n",
        "                duration = \"As prescribed\"\n",
        "                for pattern in duration_patterns:\n",
        "                    duration_match = re.search(pattern, line.upper())\n",
        "                    if duration_match:\n",
        "                        duration = duration_match.group(0)\n",
        "                        break\n",
        "\n",
        "                # Extract timing - more comprehensive\n",
        "                timing_patterns = [\n",
        "                    r'(BEFORE|AFTER|WITH)\\s*(?:MEALS?|FOOD|BREAKFAST|LUNCH|DINNER)',\n",
        "                    r'(MORNING|AFTERNOON|EVENING|NIGHT)',\n",
        "                    r'(EMPTY\\s*STOMACH|FULL\\s*STOMACH)',\n",
        "                    r'(AC|PC|HS)\\b',  # Medical timing abbreviations\n",
        "                ]\n",
        "\n",
        "                timing = \"As prescribed\"\n",
        "                for pattern in timing_patterns:\n",
        "                    timing_match = re.search(pattern, line.upper())\n",
        "                    if timing_match:\n",
        "                        timing = timing_match.group(0)\n",
        "                        break\n",
        "\n",
        "                # Only add if we have a reasonable medicine name\n",
        "                if medicine_name and len(medicine_name) > 1:\n",
        "                    medicines.append({\n",
        "                        'name': medicine_name,\n",
        "                        'dosage': dosage,\n",
        "                        'frequency': frequency,\n",
        "                        'duration': duration,\n",
        "                        'timing': timing,\n",
        "                        'original_text': original_line\n",
        "                    })\n",
        "\n",
        "        return medicines\n",
        "\n",
        "    def convert_to_plain_language(self, medicines):\n",
        "        \"\"\"Convert medical shorthand to plain language\"\"\"\n",
        "        simplified_instructions = []\n",
        "\n",
        "        for med in medicines:\n",
        "            instruction = f\"MEDICINE: {med['name']}\\n\"\n",
        "            instruction += \"=\" * 50 + \"\\n\"\n",
        "\n",
        "            # Convert frequency to plain language\n",
        "            freq = med['frequency']\n",
        "            if re.match(r'\\d+\\-\\d+\\-\\d+', freq):\n",
        "                parts = freq.split('-')\n",
        "                morning, afternoon, night = parts[0], parts[1], parts[2]\n",
        "                freq_text = []\n",
        "                if morning != '0':\n",
        "                    freq_text.append(f\"{morning} tablet(s) in the morning\")\n",
        "                if afternoon != '0':\n",
        "                    freq_text.append(f\"{afternoon} tablet(s) in the afternoon\")\n",
        "                if night != '0':\n",
        "                    freq_text.append(f\"{night} tablet(s) at night\")\n",
        "                freq_plain = \" and \".join(freq_text)\n",
        "            else:\n",
        "                freq_plain = self.medical_abbreviations.get(freq, freq)\n",
        "\n",
        "            # Build instruction\n",
        "            if med['dosage'] != \"As prescribed\":\n",
        "                instruction += f\"DOSAGE: {med['dosage']}\\n\"\n",
        "\n",
        "            instruction += f\"HOW TO TAKE: Take {freq_plain}\"\n",
        "\n",
        "            if med['timing'] != \"As prescribed\":\n",
        "                instruction += f\" {med['timing'].lower()}\"\n",
        "\n",
        "            if med['duration'] != \"As prescribed\":\n",
        "                instruction += f\" for {med['duration'].lower()}\"\n",
        "\n",
        "            instruction += \"\\n\"\n",
        "\n",
        "            # Add medicine information if available\n",
        "            med_name_lower = med['name'].lower()\n",
        "            for common_med, info in self.common_medicines.items():\n",
        "                if common_med in med_name_lower:\n",
        "                    instruction += f\"PURPOSE: This medicine is used for {info}\\n\"\n",
        "                    break\n",
        "\n",
        "            instruction += \"\\n\"\n",
        "            simplified_instructions.append(instruction)\n",
        "\n",
        "        return simplified_instructions\n",
        "\n",
        "    def translate_text(self, text, target_language):\n",
        "        \"\"\"Translate text to target language\"\"\"\n",
        "        try:\n",
        "            if target_language == 'en':\n",
        "                return text\n",
        "\n",
        "            translated = self.translator.translate(text, dest=target_language)\n",
        "            return translated.text\n",
        "        except Exception as e:\n",
        "            print(f\"Translation error: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def generate_pdf_report(self, medicines, instructions, patient_name=\"Patient\"):\n",
        "        \"\"\"Generate PDF report of simplified prescription\"\"\"\n",
        "        try:\n",
        "            pdf = FPDF()\n",
        "            pdf.add_page()\n",
        "\n",
        "            # Title\n",
        "            pdf.set_font('Arial', 'B', 20)\n",
        "            pdf.cell(0, 10, 'Simplified Prescription Report', 0, 1, 'C')\n",
        "            pdf.ln(10)\n",
        "\n",
        "            # Patient info\n",
        "            pdf.set_font('Arial', '', 12)\n",
        "            pdf.cell(0, 10, f'Patient: {patient_name}', 0, 1)\n",
        "            pdf.cell(0, 10, f'Date: {datetime.now().strftime(\"%B %d, %Y\")}', 0, 1)\n",
        "            pdf.ln(10)\n",
        "\n",
        "            # Instructions\n",
        "            pdf.set_font('Arial', 'B', 14)\n",
        "            pdf.cell(0, 10, 'Medication Instructions:', 0, 1)\n",
        "            pdf.ln(5)\n",
        "\n",
        "            pdf.set_font('Arial', '', 10)\n",
        "            for instruction in instructions:\n",
        "                # Split instruction into lines and add to PDF\n",
        "                lines = instruction.split('\\n')\n",
        "                for line in lines:\n",
        "                    if line.strip():\n",
        "                        # Handle encoding issues\n",
        "                        try:\n",
        "                            pdf.cell(0, 5, line, 0, 1)\n",
        "                        except:\n",
        "                            pdf.cell(0, 5, line.encode('latin-1', 'replace').decode('latin-1'), 0, 1)\n",
        "                pdf.ln(5)\n",
        "\n",
        "            # Important notes\n",
        "            pdf.set_font('Arial', 'B', 12)\n",
        "            pdf.cell(0, 10, 'Important Reminders:', 0, 1)\n",
        "            pdf.set_font('Arial', '', 10)\n",
        "\n",
        "            notes = [\n",
        "                \"â€¢ Always complete the full course of antibiotics even if you feel better\",\n",
        "                \"â€¢ Take medications at the same time each day\",\n",
        "                \"â€¢ Do not skip doses\",\n",
        "                \"â€¢ Contact your doctor if you experience any side effects\",\n",
        "                \"â€¢ Store medications in a cool, dry place away from children\"\n",
        "            ]\n",
        "\n",
        "            for note in notes:\n",
        "                pdf.cell(0, 5, note, 0, 1)\n",
        "\n",
        "            # Save PDF\n",
        "            pdf_filename = f'/content/prescription_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pdf'\n",
        "            pdf.output(pdf_filename)\n",
        "\n",
        "            return pdf_filename\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating PDF: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def display_results(self, medicines, instructions, original_text):\n",
        "        \"\"\"Display processing results\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"                    PRESCRIPTION PROCESSING RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(f\"\\nğŸ“‹ EXTRACTED TEXT:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(original_text)\n",
        "\n",
        "        print(f\"\\nğŸ” DETECTED LINES (DEBUG):\")\n",
        "        print(\"-\" * 50)\n",
        "        lines = original_text.split('\\n')\n",
        "        for i, line in enumerate(lines, 1):\n",
        "            if line.strip():\n",
        "                print(f\"{i:2d}: {line}\")\n",
        "\n",
        "        if medicines:\n",
        "            print(f\"\\nğŸ’Š DETECTED MEDICINES ({len(medicines)}):\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Display medicines in a more readable format\n",
        "            for i, med in enumerate(medicines, 1):\n",
        "                print(f\"\\n{i}. MEDICINE: {med['name']}\")\n",
        "                print(f\"   DOSAGE: {med['dosage']}\")\n",
        "                print(f\"   FREQUENCY: {med['frequency']}\")\n",
        "                print(f\"   DURATION: {med['duration']}\")\n",
        "                print(f\"   TIMING: {med['timing']}\")\n",
        "                print(f\"   ORIGINAL: {med['original_text']}\")\n",
        "\n",
        "            # Create DataFrame for better visualization\n",
        "            df = pd.DataFrame(medicines)\n",
        "            print(f\"\\nğŸ“Š MEDICINES TABLE:\")\n",
        "            print(\"-\" * 50)\n",
        "            print(df[['name', 'dosage', 'frequency', 'duration', 'timing']].to_string(index=False))\n",
        "\n",
        "            print(f\"\\nğŸ“– SIMPLIFIED INSTRUCTIONS:\")\n",
        "            print(\"-\" * 50)\n",
        "            for i, instruction in enumerate(instructions, 1):\n",
        "                print(f\"\\n{i}. {instruction}\")\n",
        "        else:\n",
        "            print(\"\\nâš ï¸  NO MEDICINES DETECTED\")\n",
        "            print(\"Debugging information:\")\n",
        "            print(\"- Total lines found:\", len([line for line in original_text.split('\\n') if line.strip()]))\n",
        "            print(\"- Lines with potential medicine indicators:\")\n",
        "\n",
        "            lines = original_text.split('\\n')\n",
        "            potential_medicine_lines = []\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Check for any medicine-like patterns\n",
        "                if any(pattern in line.upper() for pattern in ['TAB', 'CAP', 'SYP', 'MG', 'ML']):\n",
        "                    potential_medicine_lines.append(line)\n",
        "                elif re.search(r'\\d+', line) and len(line) > 5:\n",
        "                    potential_medicine_lines.append(line)\n",
        "\n",
        "            for line in potential_medicine_lines:\n",
        "                print(f\"  â€¢ {line}\")\n",
        "\n",
        "            if not potential_medicine_lines:\n",
        "                print(\"  â€¢ No potential medicine lines found\")\n",
        "\n",
        "            print(\"\\nPossible solutions:\")\n",
        "            print(\"â€¢ Try uploading a higher resolution image\")\n",
        "            print(\"â€¢ Ensure the image is properly oriented\")\n",
        "            print(\"â€¢ Check if the handwriting is clear\")\n",
        "            print(\"â€¢ Try scanning instead of photographing\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the prescription processor\"\"\"\n",
        "    print(\"ğŸ¥ MEDICAL PRESCRIPTION READER & SIMPLIFIER\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ğŸ“¤ Please upload your prescription image...\")\n",
        "\n",
        "    # Upload file\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"âŒ No file uploaded!\")\n",
        "        return\n",
        "\n",
        "    # Get the uploaded file\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    print(f\"âœ… File uploaded: {filename}\")\n",
        "\n",
        "    # Initialize processor\n",
        "    processor = MedicalPrescriptionProcessor()\n",
        "\n",
        "    # Process the prescription\n",
        "    print(\"\\nğŸ”„ Processing prescription...\")\n",
        "\n",
        "    # Extract text\n",
        "    extracted_text = processor.extract_text_from_image(filename)\n",
        "\n",
        "    if extracted_text:\n",
        "        print(\"âœ… Text extraction successful!\")\n",
        "\n",
        "        # Clean text\n",
        "        cleaned_text = processor.clean_text(extracted_text)\n",
        "\n",
        "        # Extract medicine information\n",
        "        medicines = processor.extract_medicine_info(cleaned_text)\n",
        "\n",
        "        # Convert to plain language\n",
        "        instructions = processor.convert_to_plain_language(medicines)\n",
        "\n",
        "        # Display results\n",
        "        processor.display_results(medicines, instructions, extracted_text)\n",
        "\n",
        "        # Ask for patient name\n",
        "        patient_name = input(\"\\nğŸ‘¤ Enter patient name (or press Enter for 'Patient'): \").strip()\n",
        "        if not patient_name:\n",
        "            patient_name = \"Patient\"\n",
        "\n",
        "        # Ask for language preference\n",
        "        print(\"\\nğŸŒ Available languages:\")\n",
        "        for i, lang in enumerate(processor.languages.keys(), 1):\n",
        "            print(f\"{i}. {lang}\")\n",
        "\n",
        "        try:\n",
        "            choice = input(\"\\nSelect language (1-11, or press Enter for English): \").strip()\n",
        "            if choice and choice.isdigit() and 1 <= int(choice) <= 11:\n",
        "                selected_lang = list(processor.languages.keys())[int(choice) - 1]\n",
        "                lang_code = processor.languages[selected_lang]\n",
        "\n",
        "                if lang_code != 'en':\n",
        "                    print(f\"\\nğŸ”„ Translating to {selected_lang}...\")\n",
        "                    translated_instructions = []\n",
        "                    for instruction in instructions:\n",
        "                        translated = processor.translate_text(instruction, lang_code)\n",
        "                        translated_instructions.append(translated)\n",
        "\n",
        "                    print(f\"\\nğŸ“– TRANSLATED INSTRUCTIONS ({selected_lang}):\")\n",
        "                    print(\"-\" * 50)\n",
        "                    for i, instruction in enumerate(translated_instructions, 1):\n",
        "                        print(f\"\\n{i}. {instruction}\")\n",
        "\n",
        "                    instructions = translated_instructions\n",
        "        except:\n",
        "            print(\"Using English as default language.\")\n",
        "\n",
        "        # Generate PDF report\n",
        "        print(\"\\nğŸ“„ Generating PDF report...\")\n",
        "        pdf_filename = processor.generate_pdf_report(medicines, instructions, patient_name)\n",
        "\n",
        "        if pdf_filename:\n",
        "            print(f\"âœ… PDF report generated: {pdf_filename}\")\n",
        "\n",
        "            # Download the PDF\n",
        "            files.download(pdf_filename)\n",
        "            print(\"ğŸ“¥ PDF report downloaded!\")\n",
        "\n",
        "        # Generate text summary\n",
        "        text_summary = f\"PRESCRIPTION SUMMARY FOR {patient_name.upper()}\\n\"\n",
        "        text_summary += f\"Date: {datetime.now().strftime('%B %d, %Y')}\\n\"\n",
        "        text_summary += \"=\"*60 + \"\\n\\n\"\n",
        "        text_summary += \"MEDICATION INSTRUCTIONS:\\n\"\n",
        "        text_summary += \"-\"*30 + \"\\n\\n\"\n",
        "\n",
        "        for instruction in instructions:\n",
        "            text_summary += instruction + \"\\n\"\n",
        "\n",
        "        text_summary += \"\\nIMPORTANT REMINDERS:\\n\"\n",
        "        text_summary += \"-\"*20 + \"\\n\"\n",
        "        text_summary += \"â€¢ Complete full course of antibiotics\\n\"\n",
        "        text_summary += \"â€¢ Take medications at same time daily\\n\"\n",
        "        text_summary += \"â€¢ Contact doctor for side effects\\n\"\n",
        "        text_summary += \"â€¢ Store in cool, dry place\\n\"\n",
        "\n",
        "        # Save text summary\n",
        "        text_filename = f'/content/prescription_summary_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt'\n",
        "        with open(text_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(text_summary)\n",
        "\n",
        "        print(f\"\\nğŸ“ Text summary saved: {text_filename}\")\n",
        "        files.download(text_filename)\n",
        "        print(\"ğŸ“¥ Text summary downloaded!\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ Could not extract text from the image.\")\n",
        "        print(\"Please try with a clearer image.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "U4fzyT6CDGjv",
        "outputId": "d84cacc2-cc17-4910-b49b-97b071be4e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¥ MEDICAL PRESCRIPTION READER & SIMPLIFIER\n",
            "============================================================\n",
            "ğŸ“¤ Please upload your prescription image...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ee46e520-ad55-4fb2-8e4b-bcf5d8e98ccb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ee46e520-ad55-4fb2-8e4b-bcf5d8e98ccb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}